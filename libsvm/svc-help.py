#-*- coding: utf-8 -*-
import os
os.chdir('c://mywork//ml//libsvm//python')
from svmutil import*
#y,x=svm_read_problem("D://libsvm.txt")
#data=svm_problem([1,-1],[[1,0,1],[-1,0,-1]]) #元组一表示分类类别
#param=svm_parameter('-c 8.0 -g 8.0')
#model=svm_train(data,param)
#svm_predict([1],[1,1,1],model)
#svm_predict([1,-1],[[1,-1,-1],[1,1,1]],model)


y, x = [1,-1], [{1:1, 2:1}, {1:-1,2:-1}]

#for i,xx in enumerate(x):
#    print i,xx


prob  = svm_problem(y, x)
param = svm_parameter('-t 0 -c 4 -b 1')
model = svm_train(prob, param)
yt = [1]
xt = [{1:1, 2:1}]
p_label, p_acc, p_val = svm_predict(yt, xt, model)

#print p_label
#print p_acc
#print p_val

#svm_train() : train an SVM model
#svm_predict() : predict testing data
#svm_read_problem() : read the data from a LIBSVM-format file.
#svm_load_model() : load a LIBSVM model.
#svm_save_model() : save model to a file.
#evaluations() : evaluate prediction results.
#
#1.svmutil中主要包含了以下几个函数：
#svmtrain()
#    训练数据. 跑SVM被戏称为 "开火車" 也是由于这个程序名而来. train会接受特定格式的输入, 产生一个 "Model" 文件.
#    这个 model 你可以想像成SVM的內部数据,因为预测要model才能预测, 不能直接吃原始数据.想想也很合理,
#    假定 train 本身是很耗时的动作, 而 train可以以某种形式存起內部数据,那下次要预测时直接把那些內部数据载入就快多了.​​​

#      There are three ways to call svm_train()
#       model = svm_train(y, x [, 'training_options'])
#       model = svm_train(prob [, 'training_options'])
#       model = svm_train(prob, param)​​
#       y: a list/tuple of l training labels (type must be int/double).
#       x: a list/tuple of l training instances.
#               The feature vector of each training instance is an instance of list/tuple or dictionary.​
#       training_options: a string in the same form as that for LIBSVM command

#iter为迭代次数，
# nu 与前面的操作参数-n nu 相同，
# obj为SVM文件转换为的二次规划求解得到的最小值，
# rho 为判决函数的常数项b，
# nSV 为支持向量个数，
# nBSV为边界上的支持向量个数，
# Total nSV为支持向量总个数。

#mode.​
#    prob: an svm_problem instance generated by calling svm_problem(y, x).For pre-computed kernel,
#            you should use svm_problem(y, x, isKernel=True)
#param: an svm_parameter instance generated by calling svm_paramete('training_options')​
#model: the returned svm_model instance.
#Options:
#-s svm类型：SVM设置类型(默认0)
#   0 -- C-SVC
#   1 --v-SVC
#   2 –一类SVM
#   3 -- e -SVR
#   4 -- v-SVR

#   -t 核函数类型：核函数设置类型（默认2）
#   0 –线性：u'v
#   1 –多项式：(r*u'v + coef0)^degree
#   2 – RBF函数：exp(-gamma|u-v|^2)
#   3 –sigmoid：tanh(r*u'v + coef0)

#   -d degree：核函数中的degree设置(针对多项式核函数)(默认3)
#   -g r(gama)：核函数中的gamma函数设置(针对多项式/rbf/sigmoid核函数)(默认1/ k)
#   -r coef0：核函数中的coef0设置(针对多项式/sigmoid核函数)((默认0)

#   -c cost：设置C-SVC，e -SVR和v-SVR的参数(损失函数)(默认1)

#   -n nu：设置v-SVC，一类SVM和v- SVR的参数(默认0.5)

#   -p p：设置e -SVR 中损失函数p的值(默认0.1)

#   -m cachesize：设置cache内存大小，以MB为单位(默认40)
#   -e eps：设置允许的终止判据(默认0.001)
#   -h shrinking：是否使用启发式，0或1(默认1)
#   -wi weight：设置第几类的参数C为weight*C(C-SVC中的C)(默认1)
#   -v n: n-fold交互检验模式，n为fold的个数，必须大于等于2

#其中-g选项中的k是指输入数据中的属性数。option -v 随机地将数据剖分为n部
#当构建完成model后，还要为上述参数选择合适的值，方法主要有Gridsearch,其他的感觉不常用，Gridsearch说白了就是穷举。
#与核函数相对应的libsvm参数：

#1）对于线性核函数，没有专门需要设置的参数
#2）对于多项式核函数，有三个参数。-d用来设置多项式核函数的最高此项次数，也就是公式中的d，默认值是3。
#-g用来设置核函数中的gamma参数设置，也就是公式中的第一个r(gamma)，默认值是1/k（k是类别数）。
#-r用来设置核函数中的coef0，也就是公式中的第二个r，默认值是0。
#3）对于RBF核函数，有一个参数。-g用来设置核函数中的gamma参数设置，也就是公式中的第一个r(gamma)，默认值是1/k（k是类别数）。
#4）对于sigmoid核函数，有两个参数。-g用来设置核函数中的gamma参数设置，也就是公式中的第一个r(gamma)，
## 默认值是1/k（k是类别数）。-r用来设置核函数中的coef0，也就是公式中的第二个r，默认值是0。

#svmpredict
#依照已经训练好的 model, 再加上给定的输入(新值), 输出預测新值所对应的类別.​
#[predicted_label, accuracy/mse, decision_values]=svmpredict(test_label, test_matrix, model, ['libsvm_options']);

#其中：
#test _label表示测试集的标签（这个值可以不知道，因为作预测的时候，本来就是想知道这个值的，这个时候，
# 随便制定一个值就可以了，只是这个时候得到的mse就没有意义了）。
# test _matrix表示测试集的属性矩阵。
# model是上面训练得到的模型。
# libsvm_options是需要设置的一系列参数。
# predicted_label表示预测得到的标签。
# accuracy/mse是一个3*1的列向量，其中第1个数字用于分类问题，表示分类准确率；后两个数字用于回归问题，
# 第2个数字表示mse；第三个数字表示平方相关系数（也就是说，如果分类的话，看第一个数字就可以了；回归的话，看后两个数字）。
# decision_values表示决策值（一般好像不怎么用）。

#svmscale
# svmscale是用来对原始样本进行缩放的, 范围可以自己定, 一般是[0,1]或[-1,1]. 缩放的目的主要是：​
# 1) 防止某个特征过大或过小, 从而在训练中起的作用不平衡;​
# 2) 为了计算速度. 因为在核计算中, 会用到内积运算或exp运算, 不平衡的数据可能造成计算困难.​
# 用法: svmscale [-l lower] [-u upper]​[-y y_lower y_upper]​[-s save_filename][-r restore_filename] filename​
# 其中, []中都是可选项:​
# -l: 设定数据下限; lower: 设定的数据下限值, 缺省为-1​
# -u: 设定数据上限; upper: 设定的数据上限值, 缺省为1​​
# -y: 是否对目标值同时进行缩放; y_lower为下限值, y_upper为上限值;​
# -s save_filename: 表示将缩放的规则保存为文件save_filename;​